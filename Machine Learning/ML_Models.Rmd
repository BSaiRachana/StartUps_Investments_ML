---
title: "R Notebook"
output:
  html_document:
    df_print: paged
---
```{r}
# OUT OF SAMPLE
# IN SAMPLE
# MODEL COMPARISION
# INTERPRETATION - also check p-values
# LDA
# QDA

library(caret)
library(doParallel)
```

```{r}
cl <- makeCluster(detectCores())
registerDoParallel(cl)
```


```{r}
#dat <- readRDS("../Dataset/Data_Cleansed.rds")
dat <- readRDS("../Dataset/Data_CE_Filtered.rds")
datCopy <- dat
#datCopy$name <- NULL
```

datCopy$market_1 <- factor(datCopy$market_1)# OUT OF SAMPLE PREDICTION
##### Need to balance the imbalance dataset first!

```{r}
# post_success
'%ni%' <- Negate('%in%')  # define 'not in' func
options(scipen=999)  # prevents printing scientific notations.

# Prep Training and Test data.
set.seed(100)
trainDataIndex <- createDataPartition(datCopy$post_success, p=0.7, list = F)  # 70% training data
trainData <- datCopy[trainDataIndex, ]
testData <- datCopy[-trainDataIndex, ]
table(trainData$post_success)
```


```{r}
# Run algorithms using 10-fold cross validation
fitControl <- trainControl(method="cv", number= 10, allowParallel = TRUE, verboseIter = TRUE)
```


```{r}
## Train a logistic regression model with 10-fold cross-validation
set.seed(100)
logit_fit <- train(post_success ~ ., data = trainData,
                   trControl = fitControl,
                   method="glm", family=binomial(link='logit'))

```

```{r}
#print(logit_fit)
```

```{r}
# In-sample performance
confusionMatrix(logit_fit)
```

```{r}
# Out-of-sample performance
confusionMatrix(predict(logit_fit, newdata = testData),
                testData$post_success, positive = '1')
```

```{r}
## Train a GBM model with 10-fold cross-validation
gbm_fit <- train(post_success ~ ., data = trainData,
                 trControl = fitControl, method = "gbm",
                 verbose=TRUE)


```

```{r}
# In-sample performance
confusionMatrix(gbm_fit)

```

```{r}
# Plot resampling profile by accuracy
#plot(gbm_fit)

```

```{r}
# Plot resampling profile by kappa statistic
#plot(gbm_fit, metric = "Kappa")

```

```{r}
# Out-of-sample performance
confusionMatrix(predict(gbm_fit, newdata = testData),
                testData$post_success, positive = '1')
```

```{r}
## Train a KNN model with 10-fold cross-validation
knn_fit <- train(post_success ~ ., data = trainData, method="knn", trControl=fitControl)
```

```{r}
# In-sample performance
confusionMatrix(knn_fit)

```

```{r}
# Plot accuracy across different n values
#plot(knn_fit)
```

```{r}
# Out-of-sample performance
confusionMatrix(predict(knn_fit, newdata = testData),
                testData$post_success, positive = '1')
```

```{r}
## Train a Random Forest model with 10-fold cross-validation
rf_fit <- train(post_success ~ ., data = trainData, method="rf", trControl=fitControl, verbose=TRUE)
```

```{r}
# In-sample performance
confusionMatrix(rf_fit)

```

```{r}
#plot(rf_fit)
```

```{r}
# Out-of-sample performance
confusionMatrix(predict(rf_fit, newdata = testData),
                testData$post_success, positive = '1')
```

```{r}
## Train a SVM model with 10-fold cross-validation
svmRadial_fit <- train(post_success ~ ., data = trainData,
                       trControl = fitControl, method = "svmRadial",
                       verbose=TRUE)
```

```{r}
# In-sample performance
confusionMatrix(svmRadial_fit)

```

```{r}
# Plot resampling profile by accuracy
#plot(svmRadial_fit)
```

```{r}
# Plot resampling profile by kappa statistic
#plot(svmRadial_fit, metric = "Kappa")
```

```{r}
# Out-of-sample performance
confusionMatrix(predict(svmRadial_fit, newdata = testData),
                testData$post_success, positive = '1')
```

```{r}
resamps <- resamples(list(Logit=logit_fit, GBM=gbm_fit, KNN=knn_fit, RF=rf_fit, SVM=svmRadial_fit))

# Summarize the resamples
summary(resamps)
```

```{r}
# Boxplots of resamples
bwplot(resamps)
```

```{r}
# Dot plots of resamples
dotplot(resamps)
```

```{r}
difValues <- diff(resamps)

summary(difValues)
```

```{r}
#bwplot(difValues, layout = c(3, 1))
dotplot(difValues)
```

```{r}
accu <- c(confusionMatrix(predict(logit_fit, newdata=testData),testData$post_success)$overall['Accuracy'],
          confusionMatrix(predict(gbm_fit, newdata=testData),testData$post_success)$overall['Accuracy'],
          confusionMatrix(predict(knn_fit, newdata=testData),testData$post_success)$overall['Accuracy'],
          confusionMatrix(predict(rf_fit, newdata=testData),testData$post_success)$overall['Accuracy'],
          confusionMatrix(predict(svmRadial_fit, newdata=testData),testData$post_success)$overall['Accuracy'])

sensi <- c(confusionMatrix(predict(logit_fit, newdata=testData),testData$post_success,positive='1')$byClass['Sensitivity'],
           confusionMatrix(predict(gbm_fit, newdata=testData),testData$post_success,positive='1')$byClass['Sensitivity'],
           confusionMatrix(predict(knn_fit, newdata=testData),testData$post_success,positive='1')$byClass['Sensitivity'],
           confusionMatrix(predict(rf_fit, newdata=testData),testData$post_success,positive='1')$byClass['Sensitivity'],
           confusionMatrix(predict(svmRadial_fit, newdata=testData),testData$post_success,positive='1')$byClass['Sensitivity'])

speci <- c(confusionMatrix(predict(logit_fit, newdata=testData),testData$post_success,positive='1')$byClass['Specificity'],
           confusionMatrix(predict(gbm_fit, newdata=testData),testData$post_success,positive='1')$byClass['Specificity'],
           confusionMatrix(predict(knn_fit, newdata=testData),testData$post_success,positive='1')$byClass['Specificity'],
           confusionMatrix(predict(rf_fit, newdata=testData),testData$post_success,positive='1')$byClass['Specificity'],
           confusionMatrix(predict(svmRadial_fit, newdata=testData),testData$post_success,positive='1')$byClass['Specificity'])

data.frame(Accuracy = round(accu,5), 
           Sensitivity = round(sensi,5), 
           Specificity = round(speci,5),
           Balanced.Accuracy = round((sensi + speci)/2,5),
           row.names = c('Logit','GBM','KNN','RF','SVM'))
```


```{r}
stopCluster(cl)
```




